# -*- coding: utf-8 -*-
"""books-scraping

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dbzs7C5M5CpRl6ZCHW3XerAcsKI9nLO-
"""

import requests
from bs4 import BeautifulSoup

import pandas as pd

url = 'https://books.toscrape.com/'

bs = BeautifulSoup(requests.get(url).text, 'html.parser')

print(bs.find('h1').text) # trial

l = bs.find('ul', class_='nav nav-list')
alist = []
if l:
    li_elements = l.find_all('li')
    for li in li_elements:
        alist.append(li)
else:
    print("No <ul> with class 'nav nav-list' found.")

links = []
for ele in alist:
  hreff = ele.find('a')
  if hreff and 'href' in hreff.attrs:
    links.append(hreff['href'])

links[:5]

base = 'https://books.toscrape.com/'

baseforbooks = 'https://books.toscrape.com/catalogue/'
booklinks = []
for i in links:
  url = base + i
  bs = BeautifulSoup(requests.get(url).text, 'html.parser')
  print(bs.find('h1').text)
  li =  bs.find_all('li',class_='col-xs-6 col-sm-4 col-md-3 col-lg-3')
  for book in li:
   h3link = book.find('h3').find('a')
   if h3link and 'href' in h3link.attrs:
    booklinks.append(baseforbooks  +  clean_book_link(h3link['href']))

# booklinks = []
# for book in li:
#    h3link = book.find('h3').find('a')
#    if h3link and 'href' in h3link.attrs:
#     booklinks.append((h3link['href']))
# #checkkk
# print(booklinks[0])

len(booklinks)

baseforbooks = 'https://books.toscrape.com/catalogue/'

def clean_book_link(link):
  while link.startswith('../') or link.startswith('../../'):
    link = link[3:] if link.startswith('../') else link[6:]
  return link

# for i in range(len(booklinks)):
#   booklinks[i] = baseforbooks +  clean_book_link(booklinks[i])

len(booklinks)

booklinks[56:60]

print(baseforbooks +'a-light-in-the-attic_1000/index.html' )

!pip install word2number
from word2number import w2n

num_words = "twenty-five"  # Example input
num_digits = w2n.word_to_num(num_words)

print(num_digits)  #output is 25

df = pd.DataFrame(columns=['Title', 'Picture', 'Price', 'Rating', 'UPC', 'Tax', 'Availability'])
for link in booklinks:
  url = link
  bs = BeautifulSoup(requests.get(url).text, 'html.parser')
  li = bs.find('div', class_='item active')
  if li:
    pic = base + ((li.find('img'))['src'])[5:]


  li = bs.find('div', class_='col-sm-6 product_main')
  if li:
    title = li.find('h1').text
    price = li.find('p', class_ = 'price_color').text
    rating = li.find('p', class_='star-rating')
    rating = w2n.word_to_num(((rating.attrs['class'])[1]).lower() )
    rating = str(rating)+'/5'


  li = bs.find('table', class_='table table-striped')
  if li:
    upc = li.find('td').text
    tax = li.find_all('td')[4].text
    availability = li.find_all('td')[5].text

  row = pd.DataFrame([{
      'Title': title, 'Picture': pic, 'Price': price,
      'Rating': rating, 'UPC': upc, 'Tax': tax, 'Availability': availability
  }])

  df = pd.concat([df, row], ignore_index=True)

# df['Title'].unique() #you can check which books are present

df.to_csv('books_data.csv', index=False)

df